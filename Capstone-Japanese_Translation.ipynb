{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japanese Translation with NLP\n",
    "\n",
    "\n",
    "## Introduction\n",
    "In this noteboook, a recurrent deep neural network will be built to translate Japanese to English.\n",
    "The completed pipeline will accept Japanese text as input and return the English translation.\n",
    "\n",
    "- **Preprocess** - You'll convert text to sequence of integers.\n",
    "- **Models** Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations. After learning about the basic types of neural networks that are often used for machine translation, you will engage in your own investigations, to design your own model!\n",
    "- **Prediction** Run the model on English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#import helper\n",
    "import os\n",
    "import numpy as np\n",
    "#import project_tests as tests\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17305676093471733455\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 15359366382519643940\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/odashi/small_parallel_enja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The corpus for this project is provided by Stanford University's Japanese English Subtitle Corpus (https://nlp.stanford.edu/projects/jesc/). THe full raw data set contains over 3 million sample sentences of Japanese and their English translation. The authors of the corpus have take the liberty to pre-tokenize the testing and training data set for ease of use.\n",
    "\n",
    "\n",
    "@ARTICLE{pryzant_jesc_2017,\n",
    "   author = {{Pryzant}, R. and {Chung}, Y. and {Jurafsky}, D. and {Britz}, D.},\n",
    "    title = \"{JESC: Japanese-English Subtitle Corpus}\",\n",
    "  journal = {ArXiv e-prints},\n",
    "archivePrefix = \"arXiv\",\n",
    "   eprint = {1710.10639},\n",
    " keywords = {Computer Science - Computation and Language},\n",
    "     year = 2017,\n",
    "    month = oct,\n",
    "}                \n",
    "    \n",
    "\n",
    "### Load Data\n",
    "The data is located in `data/*`. The tokenized training data sets are in `data/tokenzed/train.en` and `data/tokenized/train.ja` which contain the English sentences with their Japanese translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    return data.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "en_sent_token_train = load_data('data/odashi/train.en')\n",
    "en_sent_token_test = load_data('data/odashi/test.en')\n",
    "\n",
    "# Load Japanese data\n",
    "ja_sent_token_train = load_data('data/odashi/train.ja')\n",
    "ja_sent_token_test = load_data('data/odashi/test.ja')\n",
    "\n",
    "print('Dataset Loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------TRAINING DATASET-----------\n",
      "Japanese Sentence Line 1:  誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
      "English Sentence Line 1:  i can 't tell who will arrive first .\n",
      "\n",
      "Japanese Sentence Line 2:  多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
      "English Sentence Line 2:  many animals have been destroyed by men .\n",
      "\n",
      "Japanese Sentence Line 3:  私 は テニス 部員 で す 。\n",
      "English Sentence Line 3:  i 'm in the tennis club .\n",
      "\n",
      "-----------TESTING DATASET-----------\n",
      "Japanese Sentence Line 1:  彼 ら は つい に それ が 真実 だ と 認め た 。\n",
      "English Sentence Line 1:  they finally acknowledged it as true .\n",
      "\n",
      "Japanese Sentence Line 2:  彼 は 水泳 が 得意 で は な かっ た 。\n",
      "English Sentence Line 2:  he didn 't care for swimming .\n",
      "\n",
      "Japanese Sentence Line 3:  彼 は お 姉 さん に 劣 ら ず 親切 だ 。\n",
      "English Sentence Line 3:  he is no less kind than his sister .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for sample_i in range(3):\n",
    "#    print('Japanese Sentence Line {}:  {}'.format(sample_i + 1, ja_sent_raw[sample_i]))\n",
    "#    print('English Sentence Line {}:  {}'.format(sample_i + 1, en_sent_raw[sample_i]))\n",
    "    \n",
    "print(\"-----------TRAINING DATASET-----------\")\n",
    "for sample_i in range(3):    \n",
    "    print('Japanese Sentence Line {}:  {}'.format(sample_i + 1, ja_sent_token_train[sample_i]))\n",
    "    print('English Sentence Line {}:  {}'.format(sample_i + 1, en_sent_token_train[sample_i]))\n",
    "    print()\n",
    "print(\"-----------TESTING DATASET-----------\")\n",
    "for sample_i in range(3):    \n",
    "    print('Japanese Sentence Line {}:  {}'.format(sample_i + 1, ja_sent_token_test[sample_i]))\n",
    "    print('English Sentence Line {}:  {}'.format(sample_i + 1, en_sent_token_test[sample_i]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "Since Japanese does not take into account spaces between word or vocabulary. Simple split functions will not be able to be applied to distinguish words.  The tokenized dataset provided in the JESC adds the space between words, as well as underscores to distinguish beginning of words with characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391047 English tokens.\n",
      "6634 unique English tokens.\n",
      "20 Most common tokens in the English dataset:\n",
      "\".\" \"the\" \"i\" \"to\" \"you\" \"is\" \"he\" \"a\" \"?\" \"in\" \"it\" \"of\" \"she\" \"for\" \"my\" \"have\" \"'t\" \"this\" \"was\" \"me\"\n",
      "\n",
      "565618 Japanese tokens.\n",
      "8774 unique Japanese tokens.\n",
      "20 Most common tokens in the Japanese dataset:\n",
      "\"。\" \"は\" \"い\" \"に\" \"た\" \"を\" \"の\" \"て\" \"で\" \"な\" \"が\" \"彼\" \"し\" \"る\" \"私\" \"す\" \"っ\" \"ま\" \"か\" \"だ\"\n"
     ]
    }
   ],
   "source": [
    "en_words_counter = collections.Counter([word for sentence in en_sent_token_train for word in sentence.split()])\n",
    "ja_words_counter = collections.Counter([word for sentence in ja_sent_token_train for word in sentence.split()])\n",
    "\n",
    "print('{} English tokens.'.format(len([word for sentence in en_sent_token_train for word in sentence.split()])))\n",
    "print('{} unique English tokens.'.format(len(en_words_counter)))\n",
    "print('20 Most common tokens in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*en_words_counter.most_common(20)))[0]) + '\"')\n",
    "print()\n",
    "print('{} Japanese tokens.'.format(len([word for sentence in ja_sent_token_train for word in sentence.split()])))\n",
    "print('{} unique Japanese tokens.'.format(len(ja_words_counter)))\n",
    "print('20 Most common tokens in the Japanese dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*ja_words_counter.most_common(20)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_tokens</th>\n",
       "      <th>en_counts</th>\n",
       "      <th>jp_tokens</th>\n",
       "      <th>jp_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>43687</td>\n",
       "      <td>。</td>\n",
       "      <td>49522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>14383</td>\n",
       "      <td>は</td>\n",
       "      <td>35916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>13276</td>\n",
       "      <td>い</td>\n",
       "      <td>26846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>11472</td>\n",
       "      <td>に</td>\n",
       "      <td>19870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you</td>\n",
       "      <td>8872</td>\n",
       "      <td>た</td>\n",
       "      <td>19205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>8545</td>\n",
       "      <td>を</td>\n",
       "      <td>16870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>he</td>\n",
       "      <td>8401</td>\n",
       "      <td>の</td>\n",
       "      <td>16581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>7986</td>\n",
       "      <td>て</td>\n",
       "      <td>14014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?</td>\n",
       "      <td>5942</td>\n",
       "      <td>で</td>\n",
       "      <td>13108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>4791</td>\n",
       "      <td>な</td>\n",
       "      <td>11978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>it</td>\n",
       "      <td>4583</td>\n",
       "      <td>が</td>\n",
       "      <td>11631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>4212</td>\n",
       "      <td>彼</td>\n",
       "      <td>11426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>she</td>\n",
       "      <td>3742</td>\n",
       "      <td>し</td>\n",
       "      <td>10766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>for</td>\n",
       "      <td>3532</td>\n",
       "      <td>る</td>\n",
       "      <td>10353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my</td>\n",
       "      <td>3292</td>\n",
       "      <td>私</td>\n",
       "      <td>10053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   en_tokens  en_counts jp_tokens  jp_counts\n",
       "0          .      43687         。      49522\n",
       "1        the      14383         は      35916\n",
       "2          i      13276         い      26846\n",
       "3         to      11472         に      19870\n",
       "4        you       8872         た      19205\n",
       "5         is       8545         を      16870\n",
       "6         he       8401         の      16581\n",
       "7          a       7986         て      14014\n",
       "8          ?       5942         で      13108\n",
       "9         in       4791         な      11978\n",
       "10        it       4583         が      11631\n",
       "11        of       4212         彼      11426\n",
       "12       she       3742         し      10766\n",
       "13       for       3532         る      10353\n",
       "14        my       3292         私      10053"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "en_tokens = list(zip(*en_words_counter.most_common(15)))[0]\n",
    "en_counts = list(zip(*en_words_counter.most_common(15)))[1]\n",
    "jp_tokens = list(zip(*ja_words_counter.most_common(15)))[0]\n",
    "jp_counts = list(zip(*ja_words_counter.most_common(15)))[1]\n",
    "token_df = pd.DataFrame(list(zip(en_tokens,en_counts,jp_tokens, jp_counts)), columns=['en_tokens', 'en_counts', 'jp_tokens','jp_counts'])\n",
    "token_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "ax = sns.barplot(x=\"en_counts\", y=\"en_tokens\", data=token_df)\n",
    "ax.set(xlabel='Token Count', ylabel='English Tokens')\n",
    "ax.set_title('Top 15 English Tokens')\n",
    "ax.set_xlim(0,50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "ax = sns.barplot(x=\"jp_counts\", y=\"jp_tokens\", data=token_df)\n",
    "ax.set(xlabel='Token Count', ylabel='Japanese Tokens')\n",
    "ax.set_title('Top 15 Japanese Tokens')\n",
    "ax.set_xlim(0,50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Tokenize the words into ids\n",
    "2. Add padding to make all the sequences the same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize (IMPLEMENTATION)\n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "Running the cell will run `tokenize` on sample data and show output for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'t\": 3, 'i': 1, 'who': 5, 'first': 8, 'animals': 10, 'many': 9, 'by': 14, 'can': 2, \"'m\": 16, 'will': 6, 'destroyed': 13, 'club': 20, 'tell': 4, 'arrive': 7, 'in': 17, 'men': 15, 'the': 18, 'been': 12, 'tennis': 19, 'have': 11}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  i can 't tell who will arrive first .\n",
      "  Output: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Sequence 2 in x\n",
      "  Input:  many animals have been destroyed by men .\n",
      "  Output: [9, 10, 11, 12, 13, 14, 15]\n",
      "Sequence 3 in x\n",
      "  Input:  i 'm in the tennis club .\n",
      "  Output: [1, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    x_tk = Tokenizer() #tokenize to the word level\n",
    "    x_tk.fit_on_texts(x) #tokenize text x    \n",
    "    \n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = en_sent_token_train[:3]\n",
    "#    [\n",
    "\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 3 4 5 6 7 8]\n",
      "  Output: [1 2 3 4 5 6 7 8]\n",
      "Sequence 2 in x\n",
      "  Input:  [ 9 10 11 12 13 14 15]\n",
      "  Output: [ 9 10 11 12 13 14 15  0]\n",
      "Sequence 3 in x\n",
      "  Input:  [ 1 16 17 18 19 20]\n",
      "  Output: [ 1 16 17 18 19 20  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x]) # set length equal to max sequence when there is no designated length value\n",
    "    padded_sequence = pad_sequences(x, maxlen=length, padding='post')  # add 0's after sequence until sequence reaches max length\n",
    "    return padded_sequence\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Pipeline\n",
    "Your focus for this project is to build neural network architecture, so we won't ask you to create a preprocess pipeline.  Instead, we've provided you with the implementation of the `preprocess` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max Japanese sentence length: 16\n",
      "English vocabulary size: 6547\n",
      "Japanese vocabulary size: 8774\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x) # tokenize input x\n",
    "    preprocess_y, y_tk = tokenize(y) # tokenize input y\n",
    "\n",
    "    preprocess_x = pad(preprocess_x) # pad input tokenized x\n",
    "    preprocess_y = pad(preprocess_y) # pad input tokenized y\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1) # add third dimension '1'\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_ja_sentences, preproc_en_sentences, ja_tokenizer, en_tokenizer = preprocess(ja_sent_token_train, en_sent_token_train)\n",
    "\n",
    "max_en_sequence_length = preproc_en_sentences.shape[1]\n",
    "max_ja_sequence_length = preproc_ja_sentences.shape[1]\n",
    "en_vocab_size = len(en_tokenizer.word_index)\n",
    "ja_vocab_size = len(ja_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_en_sequence_length)\n",
    "print(\"Max Japanese sentence length:\", max_ja_sequence_length)\n",
    "print(\"English vocabulary size:\", en_vocab_size)\n",
    "print(\"Japanese vocabulary size:\", ja_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ids Back to Text\n",
    "The neural network will be translating the input to words ids, which isn't the final form we want.  We want the French translation.  The function `logits_to_text` will bridge the gab between the logits from the neural network to the French translation.  You'll be using this function to better understand the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 1000)          8774000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 2000)              12006000  \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 15, 2000)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 15, 2000)          18006000  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 15, 1000)          2001000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 1000)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 15, 6547)          6553547   \n",
      "=================================================================\n",
      "Total params: 47,340,547\n",
      "Trainable params: 47,340,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 103s - loss: 3.5904 - acc: 0.5476 - val_loss: nan - val_acc: 0.5732\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 102s - loss: 2.7830 - acc: 0.5754 - val_loss: nan - val_acc: 0.5785\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.6773 - acc: 0.5823 - val_loss: nan - val_acc: 0.5659\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.6059 - acc: 0.5859 - val_loss: nan - val_acc: 0.5896\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.4830 - acc: 0.5946 - val_loss: nan - val_acc: 0.5950\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.3622 - acc: 0.6008 - val_loss: nan - val_acc: 0.5993\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.2422 - acc: 0.6066 - val_loss: nan - val_acc: 0.6035\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.1323 - acc: 0.6129 - val_loss: nan - val_acc: 0.6092\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 103s - loss: 2.0235 - acc: 0.6203 - val_loss: nan - val_acc: 0.6146\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.9279 - acc: 0.6268 - val_loss: nan - val_acc: 0.6187\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.8311 - acc: 0.6349 - val_loss: nan - val_acc: 0.6249\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.7509 - acc: 0.6411 - val_loss: nan - val_acc: 0.6153\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.6825 - acc: 0.6473 - val_loss: nan - val_acc: 0.6315\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.5948 - acc: 0.6563 - val_loss: nan - val_acc: 0.6291\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.5296 - acc: 0.6633 - val_loss: nan - val_acc: 0.6370\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.4563 - acc: 0.6722 - val_loss: nan - val_acc: 0.6333\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 103s - loss: 1.3980 - acc: 0.6798 - val_loss: nan - val_acc: 0.6403\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 102s - loss: 1.3283 - acc: 0.6898 - val_loss: nan - val_acc: 0.6410\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 102s - loss: 1.2663 - acc: 0.6979 - val_loss: nan - val_acc: 0.6366\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 102s - loss: 1.2095 - acc: 0.7068 - val_loss: nan - val_acc: 0.6433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbca16387b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnn_model(input_shape, output_sequence_length, ja_vocab_size, en_vocab_size):\n",
    "    \n",
    "    \n",
    "    #parameters\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Build the layers    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #Embedding:\n",
    "    model.add(Embedding(input_dim=ja_vocab_size, output_dim=1000,  input_length=output_sequence_length, input_shape=input_shape[1:]))\n",
    "   \n",
    "\n",
    "    #Encoder   Add bidirectional recurrent layer with 1000 node layer\n",
    "    model.add(Bidirectional(GRU(1000)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "              \n",
    "              \n",
    "   # Decoder Add another bidirectional layer with 1000 node layer\n",
    "    model.add(Bidirectional(GRU(1000, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(1000, activation='relu')))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Time Distributed layer to flatten out tensor output\n",
    "    model.add(TimeDistributed(Dense(en_vocab_size, activation='softmax')))\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "print('rnn_model')\n",
    "# Train the final model\n",
    "# Reshaping the input\n",
    "tmp_x = pad(preproc_ja_sentences, max_en_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_en_sentences.shape[-2]))\n",
    "\n",
    "# Train the neural network\n",
    "rnn_model = rnn_model(\n",
    "    tmp_x.shape,\n",
    "    max_en_sequence_length,\n",
    "    ja_vocab_size,\n",
    "    en_vocab_size)\n",
    "rnn_model.fit(tmp_x, preproc_en_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "rnn_model.save('rnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = load_model('rnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    \"\"\"\n",
    "    1) Converts output of token id's back to english words\n",
    "    2) Remove padding\n",
    "    \"\"\"\n",
    "    result = logits_to_text(text, en_tokenizer)\n",
    "    result = result[:result.find(' <PAD>')]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Sentence: 彼 ら は つい に それ が 真実 だ と 認め た 。\n",
      "English Sentence: they finally acknowledged it as true .\n",
      "Model Prediction: recently day recently recently recently was recently\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the Validation Data Set\n",
    "\n",
    "preproc_ja_sentences_test, preproc_en_sentences_test, ja_tokenizer_test, en_tokenizer_test = preprocess(ja_sent_token_test, en_sent_token_test)\n",
    "\n",
    "val_x = pad(preproc_ja_sentences_test, max_en_sequence_length)\n",
    "val_x = val_x.reshape((-1, preproc_en_sentences_test.shape[-2]))\n",
    "\n",
    "output = model.predict(val_x[:1])[0]\n",
    "\n",
    "# Print prediction(s)\n",
    "print(\"Japanese Sentence:\", ja_sent_token_test[:1][0])\n",
    "print(\"English Sentence:\", en_sent_token_test[:1][0])\n",
    "print(\"Model Prediction:\", translate(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese Sentence:-- 0 彼 ら は つい に それ が 真実 だ と 認め た 。\n",
      "English Sentence:-- 0 they finally acknowledged it as true .\n",
      "Model Prediction:-- 0 recently day recently recently recently was recently\n",
      "Japanese Sentence:-- 1 彼 は 水泳 が 得意 で は な かっ た 。\n",
      "English Sentence:-- 1 he didn 't care for swimming .\n",
      "Model Prediction:-- 1 i thinks a a of of\n"
     ]
    }
   ],
   "source": [
    "#check validation translation output\n",
    "for i in range(2):\n",
    "    print(\"Japanese Sentence:--\",i, ja_sent_token_test[i:i+1][0])\n",
    "    print(\"English Sentence:--\",i, en_sent_token_test[i:i+1][0])\n",
    "    print(\"Model Prediction:--\",i, translate(model.predict(val_x[i:i+1])[0]))\n",
    "    #print(val_x[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Japanese Input</th>\n",
       "      <th>English Target</th>\n",
       "      <th>Model Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>彼 ら は つい に それ が 真実 だ と 認め た 。</td>\n",
       "      <td>they finally acknowledged it as true .</td>\n",
       "      <td>recently day recently recently recently was re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>彼 は 水泳 が 得意 で は な かっ た 。</td>\n",
       "      <td>he didn 't care for swimming .</td>\n",
       "      <td>i thinks a a of of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彼 は お 姉 さん に 劣 ら ず 親切 だ 。</td>\n",
       "      <td>he is no less kind than his sister .</td>\n",
       "      <td>where you you tower tower born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>１０ 時 前 に 戻 ら な けれ ば な ら な い 。</td>\n",
       "      <td>you must be back before ten .</td>\n",
       "      <td>it it is i i i i my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>成功 を 祈 る わ 。</td>\n",
       "      <td>break a leg .</td>\n",
       "      <td>i believe in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>彼女 は 私 たち の 隣 の 家 に す ん で い る 。</td>\n",
       "      <td>she lives next door to us .</td>\n",
       "      <td>i did it do do do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>あなた に 返事 を し よ う と し て い る ところ で す 。</td>\n",
       "      <td>i 'm about to tell you the answer .</td>\n",
       "      <td>i 'm my i i i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>私 は 刹那 的 な 生き 方 を し て い る 人間 で す 。</td>\n",
       "      <td>i 'm a person who lives for the moment .</td>\n",
       "      <td>i would like to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>この 試合 は いただ き だ 。</td>\n",
       "      <td>we have this game on ice .</td>\n",
       "      <td>what 's the wedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>こんな こと を し た 理由 を 言 い な さ い 。</td>\n",
       "      <td>will you give me your reasons for doing this ?</td>\n",
       "      <td>i is to to to to this this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>彼女 は その 先生 が 好き で す 。</td>\n",
       "      <td>she likes the teacher .</td>\n",
       "      <td>he are him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>それ が 仕事 で す 。</td>\n",
       "      <td>it 's business .</td>\n",
       "      <td>read this this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>この 靴 は 二 年 も つ で しょ う 。</td>\n",
       "      <td>these shoes will last you two years .</td>\n",
       "      <td>i 'll will on with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>彼 は 自分 の 代わり に 息子 を その 会合 に 出席 さ せ た 。</td>\n",
       "      <td>he made his son attend the meeting in his place .</td>\n",
       "      <td>he is regarded in in in in the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>行 か な い 理由 を 述べ なさ い 。</td>\n",
       "      <td>give your argument against going .</td>\n",
       "      <td>take 's for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>一 日 の 仕事 が 終わ る と 皆 家路 を 急 ぐ 。</td>\n",
       "      <td>at the end of a working day everybody is in a ...</td>\n",
       "      <td>this is a house you you you in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>私 は 彼女 の 顔 を まとも に 見 る こと が な かっ た 。</td>\n",
       "      <td>i was unable to look her in the face .</td>\n",
       "      <td>he will him with him him him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>日曜 日 の 朝 に 教会 に 行 く 人 も い る 。</td>\n",
       "      <td>some people go to church on sunday morning .</td>\n",
       "      <td>i seems to to a a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>私 は 時計 を ２ 分 進め な けれ ば な ら な い 。</td>\n",
       "      <td>i must put my watch forward two minutes .</td>\n",
       "      <td>it is is to to in in in in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>あれ は 私 が 昨日 会 っ た 少年 で す 。</td>\n",
       "      <td>that is the boy i saw yesterday .</td>\n",
       "      <td>i will me me me me help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>１０ 年 は 待 つ に は 長 い 時間 だ 。</td>\n",
       "      <td>ten years is a long time to wait .</td>\n",
       "      <td>you should to your love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>私 は 東京 で 偶然 彼 に 会 っ た 。</td>\n",
       "      <td>i met him in tokyo by chance .</td>\n",
       "      <td>he said me come come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>私 は よく 川 へ 泳ぎ に 行 く 。</td>\n",
       "      <td>i often go swimming in the river .</td>\n",
       "      <td>she was always to her her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>彼 は 大声 で 助け を 求め た 。</td>\n",
       "      <td>he called out for help .</td>\n",
       "      <td>he is to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>彼 は その 子供 を 火事 から 救い出 し た 。</td>\n",
       "      <td>he rescued the child from the fire .</td>\n",
       "      <td>i look look angry angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>彼 の 提案 に は 同意 でき な い 。</td>\n",
       "      <td>i cannot agree to his proposal .</td>\n",
       "      <td>it is to time visit to america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>私 達 は その 手紙 を 何 度 も 繰り返 し て 読 ん だ 。</td>\n",
       "      <td>we read the letter again and again .</td>\n",
       "      <td>what is the enough to to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>私 は 君 に 会え て うれし い 。</td>\n",
       "      <td>i 'm happy to see you .</td>\n",
       "      <td>kyoto is a small small city city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>お 父 さん に 手伝 っ て もら い なさ い 。</td>\n",
       "      <td>ask your dad to help you .</td>\n",
       "      <td>if you that you home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>彼 ら は その 提案 を 採択 し た 。</td>\n",
       "      <td>they adopted the proposal .</td>\n",
       "      <td>you you should be to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>私 は 彼 が 嫌い で す 。</td>\n",
       "      <td>i do not care for him .</td>\n",
       "      <td>he is is still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>それ に 超 し た こと は な い 。</td>\n",
       "      <td>nothing can be better than that .</td>\n",
       "      <td>it 's a to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>今 の ところ それ で 間に合 う で しょ う 。</td>\n",
       "      <td>this will do for now .</td>\n",
       "      <td>let 'll use you you you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>こんな の は 今日 だけ で あ っ て ほし い わ 。</td>\n",
       "      <td>i hope it will be the only one .</td>\n",
       "      <td>this is the most is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>彼女 に は 医者 で あ る 息子 が い る 。</td>\n",
       "      <td>she has a son who is a doctor .</td>\n",
       "      <td>i is the for since was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>その 先生 は 答案 を 調べ た 。</td>\n",
       "      <td>the teacher looked over the examination papers .</td>\n",
       "      <td>mr uncle is pleased of his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>彼 は 運 よ く 列車 に 間に合 っ た 。</td>\n",
       "      <td>he had the luck to catch the train .</td>\n",
       "      <td>please me me me me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>私 は 歩 い て 行 き ま す 。</td>\n",
       "      <td>i will go on foot .</td>\n",
       "      <td>i 'm there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>私 が 遅刻 し た の で 彼女 は 怒 っ た 。</td>\n",
       "      <td>she was sore at me for being late .</td>\n",
       "      <td>tell the that he is is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>私 は それ を 食べ な い ほう が 良 い 。</td>\n",
       "      <td>i 'd better not eat that .</td>\n",
       "      <td>i have the the of of of his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>喜 ん で 君 を 援助 し て あげ よ う 。</td>\n",
       "      <td>i will gladly help you .</td>\n",
       "      <td>i will stay stay you you you for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>私 は 昨日 釣り を し に 川 へ 行 っ た 。</td>\n",
       "      <td>i went fishing in the river yesterday .</td>\n",
       "      <td>you you have you you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>駅 へ 行 っ て 来 た ところ だ 。</td>\n",
       "      <td>i have been to the station .</td>\n",
       "      <td>when you i i i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>彼 は 箱 に コイン を 何 枚 か 入れ た 。</td>\n",
       "      <td>he put some coins in the box .</td>\n",
       "      <td>i is read read i i read read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>これ は 本 で す 。</td>\n",
       "      <td>this is a book .</td>\n",
       "      <td>he like everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>彼 は テーブル を 一人 占め し て しま っ た 。</td>\n",
       "      <td>he had the table to himself .</td>\n",
       "      <td>you me me my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>私 は 雨 が 降り 出 す 前 に 学校 に 着 い た 。</td>\n",
       "      <td>i reached school before the rain started .</td>\n",
       "      <td>i said to with as home home home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>その 国 は 戦争 の 準備 を し て い た 。</td>\n",
       "      <td>the country was gearing up for war .</td>\n",
       "      <td>your parents will be my parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>私 は この 歌 を よく 知 っ て い る 。</td>\n",
       "      <td>this song is familiar to me .</td>\n",
       "      <td>he is english english english english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>時 が た て ば どちら が 正し い か わか る で しょ う 。</td>\n",
       "      <td>time will tell which is right .</td>\n",
       "      <td>i will will him he happy happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>あなた の 部屋 を 掃除 し ま し た か 。</td>\n",
       "      <td>did you clean your room ?</td>\n",
       "      <td>i will be to your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>彼 は テニス が 上手 で あ る 。</td>\n",
       "      <td>he is good at tennis .</td>\n",
       "      <td>he died is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>彼 は 決して 人 の 悪口 を 言 う 人 で は な い 。</td>\n",
       "      <td>he is the last person to speak ill of others .</td>\n",
       "      <td>it is to to to to to the the the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>道路 地図 を 下さ い 。</td>\n",
       "      <td>may i have a road map ?</td>\n",
       "      <td>what 's two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>彼 の 言 う こと は 全然 わか ら な い 。</td>\n",
       "      <td>i cannot make anything of what he says .</td>\n",
       "      <td>the the boy boy is is is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>その 騒音 に 慣れ る の に 長 い 時間 かか っ た 。</td>\n",
       "      <td>it took a long time to accustom myself to the ...</td>\n",
       "      <td>please me me you you the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>そんな こと 言 う べ き で は な い 。</td>\n",
       "      <td>you ought not to say such a thing .</td>\n",
       "      <td>i can 't to to it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>これ ら は 、 なん と 良 い 本 な の だ ろ う 。</td>\n",
       "      <td>what good books these are .</td>\n",
       "      <td>this is the the story story story story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>彼 は とても 努力 し た の だ が 、 成功 し な かっ た 。</td>\n",
       "      <td>for all his efforts , he didn 't succeed .</td>\n",
       "      <td>i 'll mistakes him will will will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>どこ の ご 出身 で す か 。</td>\n",
       "      <td>where do you come from ?</td>\n",
       "      <td>i has the hand hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Japanese Input  \\\n",
       "0             彼 ら は つい に それ が 真実 だ と 認め た 。   \n",
       "1                  彼 は 水泳 が 得意 で は な かっ た 。   \n",
       "2                 彼 は お 姉 さん に 劣 ら ず 親切 だ 。   \n",
       "3             １０ 時 前 に 戻 ら な けれ ば な ら な い 。   \n",
       "4                              成功 を 祈 る わ 。   \n",
       "5           彼女 は 私 たち の 隣 の 家 に す ん で い る 。   \n",
       "6      あなた に 返事 を し よ う と し て い る ところ で す 。   \n",
       "7        私 は 刹那 的 な 生き 方 を し て い る 人間 で す 。   \n",
       "8                         この 試合 は いただ き だ 。   \n",
       "9             こんな こと を し た 理由 を 言 い な さ い 。   \n",
       "10                    彼女 は その 先生 が 好き で す 。   \n",
       "11                            それ が 仕事 で す 。   \n",
       "12                  この 靴 は 二 年 も つ で しょ う 。   \n",
       "13   彼 は 自分 の 代わり に 息子 を その 会合 に 出席 さ せ た 。   \n",
       "14                   行 か な い 理由 を 述べ なさ い 。   \n",
       "15           一 日 の 仕事 が 終わ る と 皆 家路 を 急 ぐ 。   \n",
       "16     私 は 彼女 の 顔 を まとも に 見 る こと が な かっ た 。   \n",
       "17            日曜 日 の 朝 に 教会 に 行 く 人 も い る 。   \n",
       "18         私 は 時計 を ２ 分 進め な けれ ば な ら な い 。   \n",
       "19               あれ は 私 が 昨日 会 っ た 少年 で す 。   \n",
       "20                １０ 年 は 待 つ に は 長 い 時間 だ 。   \n",
       "21                  私 は 東京 で 偶然 彼 に 会 っ た 。   \n",
       "22                    私 は よく 川 へ 泳ぎ に 行 く 。   \n",
       "23                     彼 は 大声 で 助け を 求め た 。   \n",
       "24              彼 は その 子供 を 火事 から 救い出 し た 。   \n",
       "25                   彼 の 提案 に は 同意 でき な い 。   \n",
       "26      私 達 は その 手紙 を 何 度 も 繰り返 し て 読 ん だ 。   \n",
       "27                     私 は 君 に 会え て うれし い 。   \n",
       "28              お 父 さん に 手伝 っ て もら い なさ い 。   \n",
       "29                   彼 ら は その 提案 を 採択 し た 。   \n",
       "..                                      ...   \n",
       "470                        私 は 彼 が 嫌い で す 。   \n",
       "471                   それ に 超 し た こと は な い 。   \n",
       "472             今 の ところ それ で 間に合 う で しょ う 。   \n",
       "473          こんな の は 今日 だけ で あ っ て ほし い わ 。   \n",
       "474              彼女 に は 医者 で あ る 息子 が い る 。   \n",
       "475                     その 先生 は 答案 を 調べ た 。   \n",
       "476                彼 は 運 よ く 列車 に 間に合 っ た 。   \n",
       "477                     私 は 歩 い て 行 き ま す 。   \n",
       "478             私 が 遅刻 し た の で 彼女 は 怒 っ た 。   \n",
       "479              私 は それ を 食べ な い ほう が 良 い 。   \n",
       "480               喜 ん で 君 を 援助 し て あげ よ う 。   \n",
       "481             私 は 昨日 釣り を し に 川 へ 行 っ た 。   \n",
       "482                   駅 へ 行 っ て 来 た ところ だ 。   \n",
       "483              彼 は 箱 に コイン を 何 枚 か 入れ た 。   \n",
       "484                            これ は 本 で す 。   \n",
       "485           彼 は テーブル を 一人 占め し て しま っ た 。   \n",
       "486         私 は 雨 が 降り 出 す 前 に 学校 に 着 い た 。   \n",
       "487              その 国 は 戦争 の 準備 を し て い た 。   \n",
       "488               私 は この 歌 を よく 知 っ て い る 。   \n",
       "489    時 が た て ば どちら が 正し い か わか る で しょ う 。   \n",
       "490               あなた の 部屋 を 掃除 し ま し た か 。   \n",
       "491                    彼 は テニス が 上手 で あ る 。   \n",
       "492        彼 は 決して 人 の 悪口 を 言 う 人 で は な い 。   \n",
       "493                          道路 地図 を 下さ い 。   \n",
       "494              彼 の 言 う こと は 全然 わか ら な い 。   \n",
       "495        その 騒音 に 慣れ る の に 長 い 時間 かか っ た 。   \n",
       "496                そんな こと 言 う べ き で は な い 。   \n",
       "497         これ ら は 、 なん と 良 い 本 な の だ ろ う 。   \n",
       "498    彼 は とても 努力 し た の だ が 、 成功 し な かっ た 。   \n",
       "499                       どこ の ご 出身 で す か 。   \n",
       "\n",
       "                                        English Target  \\\n",
       "0               they finally acknowledged it as true .   \n",
       "1                       he didn 't care for swimming .   \n",
       "2                 he is no less kind than his sister .   \n",
       "3                        you must be back before ten .   \n",
       "4                                        break a leg .   \n",
       "5                          she lives next door to us .   \n",
       "6                  i 'm about to tell you the answer .   \n",
       "7             i 'm a person who lives for the moment .   \n",
       "8                           we have this game on ice .   \n",
       "9       will you give me your reasons for doing this ?   \n",
       "10                             she likes the teacher .   \n",
       "11                                    it 's business .   \n",
       "12               these shoes will last you two years .   \n",
       "13   he made his son attend the meeting in his place .   \n",
       "14                  give your argument against going .   \n",
       "15   at the end of a working day everybody is in a ...   \n",
       "16              i was unable to look her in the face .   \n",
       "17        some people go to church on sunday morning .   \n",
       "18           i must put my watch forward two minutes .   \n",
       "19                   that is the boy i saw yesterday .   \n",
       "20                  ten years is a long time to wait .   \n",
       "21                      i met him in tokyo by chance .   \n",
       "22                  i often go swimming in the river .   \n",
       "23                            he called out for help .   \n",
       "24                he rescued the child from the fire .   \n",
       "25                    i cannot agree to his proposal .   \n",
       "26                we read the letter again and again .   \n",
       "27                             i 'm happy to see you .   \n",
       "28                          ask your dad to help you .   \n",
       "29                         they adopted the proposal .   \n",
       "..                                                 ...   \n",
       "470                            i do not care for him .   \n",
       "471                  nothing can be better than that .   \n",
       "472                             this will do for now .   \n",
       "473                   i hope it will be the only one .   \n",
       "474                    she has a son who is a doctor .   \n",
       "475   the teacher looked over the examination papers .   \n",
       "476               he had the luck to catch the train .   \n",
       "477                                i will go on foot .   \n",
       "478                she was sore at me for being late .   \n",
       "479                         i 'd better not eat that .   \n",
       "480                           i will gladly help you .   \n",
       "481            i went fishing in the river yesterday .   \n",
       "482                       i have been to the station .   \n",
       "483                     he put some coins in the box .   \n",
       "484                                   this is a book .   \n",
       "485                      he had the table to himself .   \n",
       "486         i reached school before the rain started .   \n",
       "487               the country was gearing up for war .   \n",
       "488                      this song is familiar to me .   \n",
       "489                    time will tell which is right .   \n",
       "490                          did you clean your room ?   \n",
       "491                             he is good at tennis .   \n",
       "492     he is the last person to speak ill of others .   \n",
       "493                            may i have a road map ?   \n",
       "494           i cannot make anything of what he says .   \n",
       "495  it took a long time to accustom myself to the ...   \n",
       "496                you ought not to say such a thing .   \n",
       "497                        what good books these are .   \n",
       "498         for all his efforts , he didn 't succeed .   \n",
       "499                           where do you come from ?   \n",
       "\n",
       "                                          Model Output  \n",
       "0    recently day recently recently recently was re...  \n",
       "1                                   i thinks a a of of  \n",
       "2                       where you you tower tower born  \n",
       "3                                  it it is i i i i my  \n",
       "4                                         i believe in  \n",
       "5                                    i did it do do do  \n",
       "6                                        i 'm my i i i  \n",
       "7                                i would like to to to  \n",
       "8                                  what 's the wedding  \n",
       "9                           i is to to to to this this  \n",
       "10                                          he are him  \n",
       "11                                      read this this  \n",
       "12                                  i 'll will on with  \n",
       "13                  he is regarded in in in in the the  \n",
       "14                                         take 's for  \n",
       "15                      this is a house you you you in  \n",
       "16                        he will him with him him him  \n",
       "17                                   i seems to to a a  \n",
       "18                          it is is to to in in in in  \n",
       "19                             i will me me me me help  \n",
       "20                             you should to your love  \n",
       "21                                he said me come come  \n",
       "22                           she was always to her her  \n",
       "23                                         he is to to  \n",
       "24                             i look look angry angry  \n",
       "25                      it is to time visit to america  \n",
       "26                   what is the enough to to to to to  \n",
       "27                    kyoto is a small small city city  \n",
       "28                                if you that you home  \n",
       "29                                you you should be to  \n",
       "..                                                 ...  \n",
       "470                                     he is is still  \n",
       "471                                      it 's a to to  \n",
       "472                            let 'll use you you you  \n",
       "473                                this is the most is  \n",
       "474                             i is the for since was  \n",
       "475                         mr uncle is pleased of his  \n",
       "476                                 please me me me me  \n",
       "477                                         i 'm there  \n",
       "478                             tell the that he is is  \n",
       "479                        i have the the of of of his  \n",
       "480                   i will stay stay you you you for  \n",
       "481                               you you have you you  \n",
       "482                                     when you i i i  \n",
       "483                       i is read read i i read read  \n",
       "484                                 he like everything  \n",
       "485                                       you me me my  \n",
       "486                   i said to with as home home home  \n",
       "487                    your parents will be my parents  \n",
       "488              he is english english english english  \n",
       "489                     i will will him he happy happy  \n",
       "490                                  i will be to your  \n",
       "491                                         he died is  \n",
       "492                   it is to to to to to the the the  \n",
       "493                                        what 's two  \n",
       "494                           the the boy boy is is is  \n",
       "495                           please me me you you the  \n",
       "496                                  i can 't to to it  \n",
       "497            this is the the story story story story  \n",
       "498                  i 'll mistakes him will will will  \n",
       "499                                i has the hand hand  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DataFrame of the Validation data and the model output\n",
    "data = []\n",
    "\n",
    "for i in range(len(ja_sent_token_test)):\n",
    "    data.append([ja_sent_token_test[i:i+1][0],en_sent_token_test[i:i+1][0],translate(model.predict(val_x[i:i+1])[0])])\n",
    "    \n",
    "valdation_df = pd.DataFrame(data, columns=['Japanese Input', 'English Target', 'Model Output'])\n",
    "\n",
    "valdation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate WER\n",
    "#Source of code below taken from here: https://martin-thoma.com/word-error-rate-calculation/\n",
    "def wer(r, h):\n",
    "    \"\"\"\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "\n",
    "    Works only for iterables up to 254 elements (uint8).\n",
    "    O(nm) time ans space complexity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : list\n",
    "    h : list\n",
    "\n",
    "    \"\"\"\n",
    "    # initialisation\n",
    "    import numpy\n",
    "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitution = d[i-1][j-1] + 1\n",
    "                insertion    = d[i][j-1] + 1\n",
    "                deletion     = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "                \n",
    "    SDI = d[len(r)][len(h)]\n",
    "    N = len(set(r+h))\n",
    "    \n",
    "    return SDI/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Japanese Input</th>\n",
       "      <th>English Target</th>\n",
       "      <th>Model Output</th>\n",
       "      <th>WER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>彼 ら は つい に それ が 真実 だ と 認め た 。</td>\n",
       "      <td>they finally acknowledged it as true .</td>\n",
       "      <td>recently day recently recently recently was re...</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>彼 は 水泳 が 得意 で は な かっ た 。</td>\n",
       "      <td>he didn 't care for swimming .</td>\n",
       "      <td>i thinks a a of of</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彼 は お 姉 さん に 劣 ら ず 親切 だ 。</td>\n",
       "      <td>he is no less kind than his sister .</td>\n",
       "      <td>where you you tower tower born</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>１０ 時 前 に 戻 ら な けれ ば な ら な い 。</td>\n",
       "      <td>you must be back before ten .</td>\n",
       "      <td>it it is i i i i my</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>成功 を 祈 る わ 。</td>\n",
       "      <td>break a leg .</td>\n",
       "      <td>i believe in</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>彼女 は 私 たち の 隣 の 家 に す ん で い る 。</td>\n",
       "      <td>she lives next door to us .</td>\n",
       "      <td>i did it do do do</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>あなた に 返事 を し よ う と し て い る ところ で す 。</td>\n",
       "      <td>i 'm about to tell you the answer .</td>\n",
       "      <td>i 'm my i i i</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>私 は 刹那 的 な 生き 方 を し て い る 人間 で す 。</td>\n",
       "      <td>i 'm a person who lives for the moment .</td>\n",
       "      <td>i would like to to to</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>この 試合 は いただ き だ 。</td>\n",
       "      <td>we have this game on ice .</td>\n",
       "      <td>what 's the wedding</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>こんな こと を し た 理由 を 言 い な さ い 。</td>\n",
       "      <td>will you give me your reasons for doing this ?</td>\n",
       "      <td>i is to to to to this this</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>彼女 は その 先生 が 好き で す 。</td>\n",
       "      <td>she likes the teacher .</td>\n",
       "      <td>he are him</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>それ が 仕事 で す 。</td>\n",
       "      <td>it 's business .</td>\n",
       "      <td>read this this</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>この 靴 は 二 年 も つ で しょ う 。</td>\n",
       "      <td>these shoes will last you two years .</td>\n",
       "      <td>i 'll will on with</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>彼 は 自分 の 代わり に 息子 を その 会合 に 出席 さ せ た 。</td>\n",
       "      <td>he made his son attend the meeting in his place .</td>\n",
       "      <td>he is regarded in in in in the the</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>行 か な い 理由 を 述べ なさ い 。</td>\n",
       "      <td>give your argument against going .</td>\n",
       "      <td>take 's for</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>一 日 の 仕事 が 終わ る と 皆 家路 を 急 ぐ 。</td>\n",
       "      <td>at the end of a working day everybody is in a ...</td>\n",
       "      <td>this is a house you you you in</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>私 は 彼女 の 顔 を まとも に 見 る こと が な かっ た 。</td>\n",
       "      <td>i was unable to look her in the face .</td>\n",
       "      <td>he will him with him him him</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>日曜 日 の 朝 に 教会 に 行 く 人 も い る 。</td>\n",
       "      <td>some people go to church on sunday morning .</td>\n",
       "      <td>i seems to to a a</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>私 は 時計 を ２ 分 進め な けれ ば な ら な い 。</td>\n",
       "      <td>i must put my watch forward two minutes .</td>\n",
       "      <td>it is is to to in in in in</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>あれ は 私 が 昨日 会 っ た 少年 で す 。</td>\n",
       "      <td>that is the boy i saw yesterday .</td>\n",
       "      <td>i will me me me me help</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>１０ 年 は 待 つ に は 長 い 時間 だ 。</td>\n",
       "      <td>ten years is a long time to wait .</td>\n",
       "      <td>you should to your love</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>私 は 東京 で 偶然 彼 に 会 っ た 。</td>\n",
       "      <td>i met him in tokyo by chance .</td>\n",
       "      <td>he said me come come</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>私 は よく 川 へ 泳ぎ に 行 く 。</td>\n",
       "      <td>i often go swimming in the river .</td>\n",
       "      <td>she was always to her her</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>彼 は 大声 で 助け を 求め た 。</td>\n",
       "      <td>he called out for help .</td>\n",
       "      <td>he is to to</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>彼 は その 子供 を 火事 から 救い出 し た 。</td>\n",
       "      <td>he rescued the child from the fire .</td>\n",
       "      <td>i look look angry angry</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>彼 の 提案 に は 同意 でき な い 。</td>\n",
       "      <td>i cannot agree to his proposal .</td>\n",
       "      <td>it is to time visit to america</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>私 達 は その 手紙 を 何 度 も 繰り返 し て 読 ん だ 。</td>\n",
       "      <td>we read the letter again and again .</td>\n",
       "      <td>what is the enough to to to to to</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>私 は 君 に 会え て うれし い 。</td>\n",
       "      <td>i 'm happy to see you .</td>\n",
       "      <td>kyoto is a small small city city</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>お 父 さん に 手伝 っ て もら い なさ い 。</td>\n",
       "      <td>ask your dad to help you .</td>\n",
       "      <td>if you that you home</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>彼 ら は その 提案 を 採択 し た 。</td>\n",
       "      <td>they adopted the proposal .</td>\n",
       "      <td>you you should be to</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>私 は 彼 が 嫌い で す 。</td>\n",
       "      <td>i do not care for him .</td>\n",
       "      <td>he is is still</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>それ に 超 し た こと は な い 。</td>\n",
       "      <td>nothing can be better than that .</td>\n",
       "      <td>it 's a to to</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>今 の ところ それ で 間に合 う で しょ う 。</td>\n",
       "      <td>this will do for now .</td>\n",
       "      <td>let 'll use you you you</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>こんな の は 今日 だけ で あ っ て ほし い わ 。</td>\n",
       "      <td>i hope it will be the only one .</td>\n",
       "      <td>this is the most is</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>彼女 に は 医者 で あ る 息子 が い る 。</td>\n",
       "      <td>she has a son who is a doctor .</td>\n",
       "      <td>i is the for since was</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>その 先生 は 答案 を 調べ た 。</td>\n",
       "      <td>the teacher looked over the examination papers .</td>\n",
       "      <td>mr uncle is pleased of his</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>彼 は 運 よ く 列車 に 間に合 っ た 。</td>\n",
       "      <td>he had the luck to catch the train .</td>\n",
       "      <td>please me me me me</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>私 は 歩 い て 行 き ま す 。</td>\n",
       "      <td>i will go on foot .</td>\n",
       "      <td>i 'm there</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>私 が 遅刻 し た の で 彼女 は 怒 っ た 。</td>\n",
       "      <td>she was sore at me for being late .</td>\n",
       "      <td>tell the that he is is</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>私 は それ を 食べ な い ほう が 良 い 。</td>\n",
       "      <td>i 'd better not eat that .</td>\n",
       "      <td>i have the the of of of his</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>喜 ん で 君 を 援助 し て あげ よ う 。</td>\n",
       "      <td>i will gladly help you .</td>\n",
       "      <td>i will stay stay you you you for</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>私 は 昨日 釣り を し に 川 へ 行 っ た 。</td>\n",
       "      <td>i went fishing in the river yesterday .</td>\n",
       "      <td>you you have you you</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>駅 へ 行 っ て 来 た ところ だ 。</td>\n",
       "      <td>i have been to the station .</td>\n",
       "      <td>when you i i i</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>彼 は 箱 に コイン を 何 枚 か 入れ た 。</td>\n",
       "      <td>he put some coins in the box .</td>\n",
       "      <td>i is read read i i read read</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>これ は 本 で す 。</td>\n",
       "      <td>this is a book .</td>\n",
       "      <td>he like everything</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>彼 は テーブル を 一人 占め し て しま っ た 。</td>\n",
       "      <td>he had the table to himself .</td>\n",
       "      <td>you me me my</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>私 は 雨 が 降り 出 す 前 に 学校 に 着 い た 。</td>\n",
       "      <td>i reached school before the rain started .</td>\n",
       "      <td>i said to with as home home home</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>その 国 は 戦争 の 準備 を し て い た 。</td>\n",
       "      <td>the country was gearing up for war .</td>\n",
       "      <td>your parents will be my parents</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>私 は この 歌 を よく 知 っ て い る 。</td>\n",
       "      <td>this song is familiar to me .</td>\n",
       "      <td>he is english english english english</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>時 が た て ば どちら が 正し い か わか る で しょ う 。</td>\n",
       "      <td>time will tell which is right .</td>\n",
       "      <td>i will will him he happy happy</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>あなた の 部屋 を 掃除 し ま し た か 。</td>\n",
       "      <td>did you clean your room ?</td>\n",
       "      <td>i will be to your</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>彼 は テニス が 上手 で あ る 。</td>\n",
       "      <td>he is good at tennis .</td>\n",
       "      <td>he died is</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>彼 は 決して 人 の 悪口 を 言 う 人 で は な い 。</td>\n",
       "      <td>he is the last person to speak ill of others .</td>\n",
       "      <td>it is to to to to to the the the</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>道路 地図 を 下さ い 。</td>\n",
       "      <td>may i have a road map ?</td>\n",
       "      <td>what 's two</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>彼 の 言 う こと は 全然 わか ら な い 。</td>\n",
       "      <td>i cannot make anything of what he says .</td>\n",
       "      <td>the the boy boy is is is</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>その 騒音 に 慣れ る の に 長 い 時間 かか っ た 。</td>\n",
       "      <td>it took a long time to accustom myself to the ...</td>\n",
       "      <td>please me me you you the</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>そんな こと 言 う べ き で は な い 。</td>\n",
       "      <td>you ought not to say such a thing .</td>\n",
       "      <td>i can 't to to it</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>これ ら は 、 なん と 良 い 本 な の だ ろ う 。</td>\n",
       "      <td>what good books these are .</td>\n",
       "      <td>this is the the story story story story</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>彼 は とても 努力 し た の だ が 、 成功 し な かっ た 。</td>\n",
       "      <td>for all his efforts , he didn 't succeed .</td>\n",
       "      <td>i 'll mistakes him will will will</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>どこ の ご 出身 で す か 。</td>\n",
       "      <td>where do you come from ?</td>\n",
       "      <td>i has the hand hand</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Japanese Input  \\\n",
       "0             彼 ら は つい に それ が 真実 だ と 認め た 。   \n",
       "1                  彼 は 水泳 が 得意 で は な かっ た 。   \n",
       "2                 彼 は お 姉 さん に 劣 ら ず 親切 だ 。   \n",
       "3             １０ 時 前 に 戻 ら な けれ ば な ら な い 。   \n",
       "4                              成功 を 祈 る わ 。   \n",
       "5           彼女 は 私 たち の 隣 の 家 に す ん で い る 。   \n",
       "6      あなた に 返事 を し よ う と し て い る ところ で す 。   \n",
       "7        私 は 刹那 的 な 生き 方 を し て い る 人間 で す 。   \n",
       "8                         この 試合 は いただ き だ 。   \n",
       "9             こんな こと を し た 理由 を 言 い な さ い 。   \n",
       "10                    彼女 は その 先生 が 好き で す 。   \n",
       "11                            それ が 仕事 で す 。   \n",
       "12                  この 靴 は 二 年 も つ で しょ う 。   \n",
       "13   彼 は 自分 の 代わり に 息子 を その 会合 に 出席 さ せ た 。   \n",
       "14                   行 か な い 理由 を 述べ なさ い 。   \n",
       "15           一 日 の 仕事 が 終わ る と 皆 家路 を 急 ぐ 。   \n",
       "16     私 は 彼女 の 顔 を まとも に 見 る こと が な かっ た 。   \n",
       "17            日曜 日 の 朝 に 教会 に 行 く 人 も い る 。   \n",
       "18         私 は 時計 を ２ 分 進め な けれ ば な ら な い 。   \n",
       "19               あれ は 私 が 昨日 会 っ た 少年 で す 。   \n",
       "20                １０ 年 は 待 つ に は 長 い 時間 だ 。   \n",
       "21                  私 は 東京 で 偶然 彼 に 会 っ た 。   \n",
       "22                    私 は よく 川 へ 泳ぎ に 行 く 。   \n",
       "23                     彼 は 大声 で 助け を 求め た 。   \n",
       "24              彼 は その 子供 を 火事 から 救い出 し た 。   \n",
       "25                   彼 の 提案 に は 同意 でき な い 。   \n",
       "26      私 達 は その 手紙 を 何 度 も 繰り返 し て 読 ん だ 。   \n",
       "27                     私 は 君 に 会え て うれし い 。   \n",
       "28              お 父 さん に 手伝 っ て もら い なさ い 。   \n",
       "29                   彼 ら は その 提案 を 採択 し た 。   \n",
       "..                                      ...   \n",
       "470                        私 は 彼 が 嫌い で す 。   \n",
       "471                   それ に 超 し た こと は な い 。   \n",
       "472             今 の ところ それ で 間に合 う で しょ う 。   \n",
       "473          こんな の は 今日 だけ で あ っ て ほし い わ 。   \n",
       "474              彼女 に は 医者 で あ る 息子 が い る 。   \n",
       "475                     その 先生 は 答案 を 調べ た 。   \n",
       "476                彼 は 運 よ く 列車 に 間に合 っ た 。   \n",
       "477                     私 は 歩 い て 行 き ま す 。   \n",
       "478             私 が 遅刻 し た の で 彼女 は 怒 っ た 。   \n",
       "479              私 は それ を 食べ な い ほう が 良 い 。   \n",
       "480               喜 ん で 君 を 援助 し て あげ よ う 。   \n",
       "481             私 は 昨日 釣り を し に 川 へ 行 っ た 。   \n",
       "482                   駅 へ 行 っ て 来 た ところ だ 。   \n",
       "483              彼 は 箱 に コイン を 何 枚 か 入れ た 。   \n",
       "484                            これ は 本 で す 。   \n",
       "485           彼 は テーブル を 一人 占め し て しま っ た 。   \n",
       "486         私 は 雨 が 降り 出 す 前 に 学校 に 着 い た 。   \n",
       "487              その 国 は 戦争 の 準備 を し て い た 。   \n",
       "488               私 は この 歌 を よく 知 っ て い る 。   \n",
       "489    時 が た て ば どちら が 正し い か わか る で しょ う 。   \n",
       "490               あなた の 部屋 を 掃除 し ま し た か 。   \n",
       "491                    彼 は テニス が 上手 で あ る 。   \n",
       "492        彼 は 決して 人 の 悪口 を 言 う 人 で は な い 。   \n",
       "493                          道路 地図 を 下さ い 。   \n",
       "494              彼 の 言 う こと は 全然 わか ら な い 。   \n",
       "495        その 騒音 に 慣れ る の に 長 い 時間 かか っ た 。   \n",
       "496                そんな こと 言 う べ き で は な い 。   \n",
       "497         これ ら は 、 なん と 良 い 本 な の だ ろ う 。   \n",
       "498    彼 は とても 努力 し た の だ が 、 成功 し な かっ た 。   \n",
       "499                       どこ の ご 出身 で す か 。   \n",
       "\n",
       "                                        English Target  \\\n",
       "0               they finally acknowledged it as true .   \n",
       "1                       he didn 't care for swimming .   \n",
       "2                 he is no less kind than his sister .   \n",
       "3                        you must be back before ten .   \n",
       "4                                        break a leg .   \n",
       "5                          she lives next door to us .   \n",
       "6                  i 'm about to tell you the answer .   \n",
       "7             i 'm a person who lives for the moment .   \n",
       "8                           we have this game on ice .   \n",
       "9       will you give me your reasons for doing this ?   \n",
       "10                             she likes the teacher .   \n",
       "11                                    it 's business .   \n",
       "12               these shoes will last you two years .   \n",
       "13   he made his son attend the meeting in his place .   \n",
       "14                  give your argument against going .   \n",
       "15   at the end of a working day everybody is in a ...   \n",
       "16              i was unable to look her in the face .   \n",
       "17        some people go to church on sunday morning .   \n",
       "18           i must put my watch forward two minutes .   \n",
       "19                   that is the boy i saw yesterday .   \n",
       "20                  ten years is a long time to wait .   \n",
       "21                      i met him in tokyo by chance .   \n",
       "22                  i often go swimming in the river .   \n",
       "23                            he called out for help .   \n",
       "24                he rescued the child from the fire .   \n",
       "25                    i cannot agree to his proposal .   \n",
       "26                we read the letter again and again .   \n",
       "27                             i 'm happy to see you .   \n",
       "28                          ask your dad to help you .   \n",
       "29                         they adopted the proposal .   \n",
       "..                                                 ...   \n",
       "470                            i do not care for him .   \n",
       "471                  nothing can be better than that .   \n",
       "472                             this will do for now .   \n",
       "473                   i hope it will be the only one .   \n",
       "474                    she has a son who is a doctor .   \n",
       "475   the teacher looked over the examination papers .   \n",
       "476               he had the luck to catch the train .   \n",
       "477                                i will go on foot .   \n",
       "478                she was sore at me for being late .   \n",
       "479                         i 'd better not eat that .   \n",
       "480                           i will gladly help you .   \n",
       "481            i went fishing in the river yesterday .   \n",
       "482                       i have been to the station .   \n",
       "483                     he put some coins in the box .   \n",
       "484                                   this is a book .   \n",
       "485                      he had the table to himself .   \n",
       "486         i reached school before the rain started .   \n",
       "487               the country was gearing up for war .   \n",
       "488                      this song is familiar to me .   \n",
       "489                    time will tell which is right .   \n",
       "490                          did you clean your room ?   \n",
       "491                             he is good at tennis .   \n",
       "492     he is the last person to speak ill of others .   \n",
       "493                            may i have a road map ?   \n",
       "494           i cannot make anything of what he says .   \n",
       "495  it took a long time to accustom myself to the ...   \n",
       "496                you ought not to say such a thing .   \n",
       "497                        what good books these are .   \n",
       "498         for all his efforts , he didn 't succeed .   \n",
       "499                           where do you come from ?   \n",
       "\n",
       "                                          Model Output       WER  \n",
       "0    recently day recently recently recently was re...  0.700000  \n",
       "1                                   i thinks a a of of  0.636364  \n",
       "2                       where you you tower tower born  0.692308  \n",
       "3                                  it it is i i i i my  0.727273  \n",
       "4                                         i believe in  0.571429  \n",
       "5                                    i did it do do do  0.636364  \n",
       "6                                        i 'm my i i i  0.700000  \n",
       "7                                i would like to to to  0.692308  \n",
       "8                                  what 's the wedding  0.636364  \n",
       "9                           i is to to to to this this  0.692308  \n",
       "10                                          he are him  0.625000  \n",
       "11                                      read this this  0.666667  \n",
       "12                                  i 'll will on with  0.583333  \n",
       "13                  he is regarded in in in in the the  0.750000  \n",
       "14                                         take 's for  0.666667  \n",
       "15                      this is a house you you you in  0.777778  \n",
       "16                        he will him with him him him  0.714286  \n",
       "17                                   i seems to to a a  0.666667  \n",
       "18                          it is is to to in in in in  0.692308  \n",
       "19                             i will me me me me help  0.727273  \n",
       "20                             you should to your love  0.615385  \n",
       "21                                he said me come come  0.666667  \n",
       "22                           she was always to her her  0.615385  \n",
       "23                                         he is to to  0.625000  \n",
       "24                             i look look angry angry  0.800000  \n",
       "25                      it is to time visit to america  0.583333  \n",
       "26                   what is the enough to to to to to  0.727273  \n",
       "27                    kyoto is a small small city city  0.583333  \n",
       "28                                if you that you home  0.600000  \n",
       "29                                you you should be to  0.555556  \n",
       "..                                                 ...       ...  \n",
       "470                                     he is is still  0.700000  \n",
       "471                                      it 's a to to  0.636364  \n",
       "472                            let 'll use you you you  0.600000  \n",
       "473                                this is the most is  0.666667  \n",
       "474                             i is the for since was  0.692308  \n",
       "475                         mr uncle is pleased of his  0.615385  \n",
       "476                                 please me me me me  0.900000  \n",
       "477                                         i 'm there  0.625000  \n",
       "478                             tell the that he is is  0.642857  \n",
       "479                        i have the the of of of his  0.636364  \n",
       "480                   i will stay stay you you you for  0.625000  \n",
       "481                               you you have you you  0.800000  \n",
       "482                                     when you i i i  0.777778  \n",
       "483                       i is read read i i read read  0.727273  \n",
       "484                                 he like everything  0.625000  \n",
       "485                                       you me me my  0.700000  \n",
       "486                   i said to with as home home home  0.538462  \n",
       "487                    your parents will be my parents  0.615385  \n",
       "488              he is english english english english  0.666667  \n",
       "489                     i will will him he happy happy  0.545455  \n",
       "490                                  i will be to your  0.600000  \n",
       "491                                         he died is  0.714286  \n",
       "492                   it is to to to to to the the the  0.750000  \n",
       "493                                        what 's two  0.700000  \n",
       "494                           the the boy boy is is is  0.750000  \n",
       "495                           please me me you you the  0.785714  \n",
       "496                                  i can 't to to it  0.615385  \n",
       "497            this is the the story story story story  0.800000  \n",
       "498                  i 'll mistakes him will will will  0.666667  \n",
       "499                                i has the hand hand  0.600000  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add WER column comparing the English Target sentence with the Model Output\n",
    "valdation_df['WER'] = valdation_df.apply(lambda row: wer(row['English Target'].split(), row['Model Output'].split()), axis=1)\n",
    "valdation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean       0.685800\n",
       "std        0.098464\n",
       "min        0.428571\n",
       "25%        0.622596\n",
       "50%        0.666667\n",
       "75%        0.737500\n",
       "max        1.250000\n",
       "Name: WER, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add summary statistics\n",
    "valdation_df['WER'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
