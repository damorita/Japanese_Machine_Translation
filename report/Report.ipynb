{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Daniel Lameyer  \n",
    "6/01/2019\n",
    "\n",
    "## I. Definition\n",
    "[//]: # (_approx. 1-2 pages_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Project Overview\n",
    "Deep Learning technology has exponentially expanded the possibilities of machine learning capabilities in recent years. One of the most popular applications of which is in natural language processing and language translation due to the the technology's ability to process the complicated structure that is human language. Thanks to advancements in this field, in 2016, Google announced that it's popular Google Translate services will transition to artificial neural network based algorithms as the foundation of its translation software. Among the various deep neural network architectures, the Recurrent Nueral Network structure is commonly used for NLP tasks due to the temporal & sequential structure of languages. [Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/pdf/1609.08144.pdf)\n",
    "\n",
    "In this project, I created a machine learning model that can translate a Japanese sentences to English. Translating between Japanese and English is notoriously difficult due to the vast linguistic differences in the structure, grammar, and vocabulary of the languages. Languages with similar roots or linguistic history are often easier to translate to each other both by humans and machines. However, dissimilar languages often have an added challenge. This project is inspired by this article where an RNN model was built to translate English to French [Language Translation with RNN](https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571). The dataset for this project will utilize the corpus provided by [Yusuke Oda](https://github.com/odashi/small_parallel_enja).\n",
    "\n",
    "----\n",
    "[//]: # (\n",
    "In this section, look to provide a high-level overview of the project in layman’s terms. Questions to ask yourself when writing this section:\n",
    "- _Has an overview of the project been provided, such as the problem domain, project origin, and related datasets or input data?_\n",
    "- _Has enough background information been given so that an uninformed reader would understand the problem domain and following problem statement?_\n",
    ")\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The objective of this project is to build a model, learned using data samples of Japanese sentences with their English translations, that will automatically return the translated English sentence when a new Japanese sentences has been passed to it. \n",
    "The tasks will take the following steps:\n",
    "1. Import the Japanese and English sentence datasets\n",
    "2. Preprocess the dataset into tokens, numerical representations and padded vectors.\n",
    "3. Train a RNN model over the preprocessed training data set\n",
    "4. Make the model translated Japanese sentences into English\n",
    "5. Test and Score the performance of the model using Word Error Rate\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will want to clearly define the problem that you are trying to solve, including the strategy outline of tasks you will use to achieve the desired solution. You should also thoroughly discuss what the intended solution will be for this problem. Questions to ask yourself when writing this section:\n",
    "- _Is the problem statement clearly defined? Will the reader understand what you are expecting to solve?_\n",
    "- _Have you thoroughly discussed how you will attempt to solve the problem?_\n",
    "- _Is an anticipated solution clearly defined? Will the reader understand what results you are looking for?_\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "### Metrics\n",
    "\n",
    "The basis of the evaluation will be to compare the English sentence the model produces, against the appropriate label sentence which the model was intended to produce. Since translation can be a very difficult concept to score with multiple methods to evaluate, there are numerous options to be selected here. The proposed evaluation metric is to utilize the [Word Error Rate](https://en.wikipedia.org/wiki/Word_error_rate) to evaluate a score between the the model output and target sentence.\n",
    "\n",
    "The Word Error rate calculation is as follows:\n",
    "WER = (S+D+I) / N  = (S+D+I) / (S+D+C)\n",
    "\n",
    "Where S is the number of substitutions, D is the number of deletions, I is the number of insertions, C is the number of correct words, and N is the number of words in the reference (N=S+D+C).  This methodology provides a simple yet effective method to determine how closely a sentece resembles another. \n",
    "\n",
    "It is important to take note that one shortfall of this method is that the semantics of the original sentence is not taken into considerations. Although word selection may closely resemble the target sentence, words out of order or small differences in diction can vastly alter the intended meaning of the original sentence. \n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to clearly define the metrics or calculations you will use to measure performance of a model or result in your project. These calculations and metrics should be justified based on the characteristics of the problem and problem domain. Questions to ask yourself when writing this section:\n",
    "- _Are the metrics you’ve chosen to measure the performance of your models clearly discussed and defined?_\n",
    "- _Have you provided reasonable justification for the metrics chosen based on the problem and solution?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## II. Analysis\n",
    "[//]: # (_approx. 2-4 pages_)\n",
    "\n",
    "### Data Exploration\n",
    "[//]: # (\n",
    "In this section, you will be expected to analyze the data you are using for the problem. This data can either be in the form of a dataset or datasets, input data or input files, or even an environment. The type of data should be thoroughly described and, if possible, have basic statistics and information presented such as discussion of input features or defining characteristics about the input or environment. Any abnormalities or interesting qualities about the data that may need to be addressed have been identified such as features that need to be transformed or the possibility of outliers. Questions to ask yourself when writing this section:\n",
    "- _If a dataset is present for this problem, have you thoroughly discussed certain features about the dataset? Has a data sample been provided to the reader?_\n",
    "- _If a dataset is present for this problem, are statistics about the dataset calculated and reported? Have any relevant results from this calculation been discussed?_\n",
    "- _If a dataset is **not** present for this problem, has discussion been made about the input space or input data for your problem?_\n",
    "- _Are there any abnormalities or characteristics about the input space or dataset that need to be addressed? categorical variables, missing values, outliers, etc._\n",
    "\n",
    ")\n",
    "\n",
    "The dataset for this project will utilize the corpus provided by [Yusuke Oda](https://github.com/odashi/small_parallel_enja) which is a sample of the [Tanaka Corpus](http://www.edrdg.org/wiki/index.php/Tanaka_Corpus). Yuseke Oda has taken the Tanaka Corpus and preprocessed the data for easier consumption for machine translation models. The corpus training dataset contains 50,000 Japanese - English sentence pairs, and the validation dataset is 500 sentence pairs.  All of sentences are pretokenized using Stanford Tokenizer and KyTea, with each sentence between 4~16 words in length. The sentences provided in the Oda corpus do not share a common topic or theme and vary in vocabulary. All of the English sentences are contained in files ending with a '.en' while all the Japanese sentences are in files ending with '.ja'. Each translation pair occupies the the same line position in it's complimentary file. For example, the English translation to the first line in train.ja is the first line in train.en.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.1:__\n",
    "A sample of the first three sentence pairs of the training and validation datasets are printed below.\n",
    "\n",
    "<img src=\"images/SampleSentences.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exploratory Visualization\n",
    "\n",
    "In the priliminary exploration of the data, the training data set was tokenized into individual characters and words so that the deep learning model can learn to translate a Japanese token to the it's English equivalent. After basic preprocessing, the summary statistics of the dataset have been provided below including total token count, unique token count, and most common toekns per language data set. As expected, most of the tokens are articles, pronouns, conjuctions and prepositions that connect nouns, verbs and adjectives. Most of the tokens that hold semantic value are less frequent in the dataset.\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to provide some form of visualization that summarizes or extracts a relevant characteristic or feature about the data. The visualization should adequately support the data being used. Discuss why this visualization was chosen and how it is relevant. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant characteristic or feature about the dataset or input data?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_\n",
    "\n",
    "----------)\n",
    "\n",
    "__Fig2:__\n",
    "Summarized characteristics of the Japanese and English training data sets.\n",
    "<img src=\"images/Tokens.png\">\n",
    "\n",
    "__Fig3:__\n",
    "Barplot displaying the frequency of the 15 most common tokens in the English and Japanese training datasets. _Note_ Seaborn packages fails to display Japanese characters. The axis aligns with order of tokens displayed in Fig2.\n",
    "<img src=\"images/token_chart.png\">\n",
    "\n",
    "\n",
    "Within Initial Observations,it can be seen that the English tokens are primarily broken down by words with a few reflecting punctuations (e.g. \".\") or contractions (e.g. \"'t\").\n",
    "\n",
    "The Japanese tokens on the other hand, the most common tokens are reflected by inidividual characters rather than words that may carry sematics or meanings. Due to the grammatical nature of Japanese, most of these tokens (combination of tokens) reflect the register or conjugation of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques\n",
    "\n",
    "The translation model is a Recurrent Neural Network, which is the most popular and effective machine learning model for natural language processing and machine translation tasks. RNN are particularly effective due to the it's sequential archtecture which relies on new inputs and outputs from the previous input. The model will need to have a large data set to train on with frequent and different examples of how words are translated.\n",
    "\n",
    "__Training Parameters:__\n",
    "- Number of Epics\n",
    "- Training/Test breakdown\n",
    "- Batch size\n",
    "- Dropout Rate\n",
    "- Learning Rate\n",
    "\n",
    "__Neural network Architecture:__\n",
    "- Number of (hidden) layers\n",
    "- number of nodes per layer\n",
    "- Layer type (Bidirectional, GRU, etc)\n",
    "\n",
    "Techincal Requirement:\n",
    "The model requires a GPU for the processing of random batches as it trains on the data set. An AWS EC2 instance of p2.xlarge was utilized to train the model an reduce training time.\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to discuss the algorithms and techniques you intend to use for solving the problem. You should justify the use of each one based on the characteristics of the problem and the problem domain. Questions to ask yourself when writing this section:\n",
    "- _Are the algorithms you will use, including any default variables/parameters in the project clearly defined?_\n",
    "- _Are the techniques to be used thoroughly discussed and justified?_\n",
    "- _Is it made clear how the input data or datasets will be handled by the algorithms and techniques chosen?_\n",
    ")\n",
    "\n",
    "--------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Benchmark\n",
    "\n",
    "Much like Google’s Neural Machine Translation System the basis of this model will be a deep neural network with an RNN architecture. Recurrent Neural Networks are a very common archtecture for NLP machine learning tasks due to the sequential nature of human languages. The RNN may contain addtional hidden layers and bidirectiobnal architectures due to the complexity of the linguistic difference between Japanese and English. In an effort to obtain similar performance based on other RNN models built for machine translation, the author will aim for a validation score of 97.5% achieved by Thomas Tracey in his Englsih to French [translation model](https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571). The inspiration for the architecture will also borrow concepts outlined in Eric Greenstein and Daniel Penner's research on [Japanese-to-EnglishMachineTranslationUsing RecurrentNeuralNetworks](https://cs224d.stanford.edu/reports/GreensteinEric.pdf)\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to provide a clearly defined benchmark result or threshold for comparing across performances obtained by your solution. The reasoning behind the benchmark in the case where it is not an established result should be discussed. Questions to ask yourself when writing this section:\n",
    "- _Has some result or value been provided that acts as a benchmark for measuring performance?_\n",
    "- _Is it clear how this result or value was obtained whether by data or by hypothesi?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology\n",
    "_(approx. 3-5 pages)_\n",
    "\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "Before the model can be built, the raw data will need to be preprocessed before the training step.\n",
    "These steps include:\n",
    "    1. Tokenizing the sentences into individual tokens\n",
    "    2. Create a dictionary of unique numerical ids per token\n",
    "    3. Convert arrays of tokens to unique ids\n",
    "    4. Add padding to arrays of tokenized ids so all arrays are fixed length\n",
    "    5. Reshape the padded arrays for model input\n",
    "\n",
    "After the RNN model has trained across the preprocessed sentences, the model will output a padded array of ids. The output array will need to be unpadded, and reconverted to english words.\n",
    "\n",
    "[//]: # (\n",
    "In this section, all of your preprocessing steps will need to be clearly documented, if any were necessary. From the previous section, any of the abnormalities or characteristics that you identified about the dataset will be addressed and corrected here. Questions to ask yourself when writing this section:\n",
    "- _If the algorithms chosen require preprocessing steps like feature selection or feature transformations, have they been properly documented?_\n",
    "- _Based on the **Data Exploration** section, if there were abnormalities or characteristics that needed to be addressed, have they been properly corrected?_\n",
    "- _If no preprocessing is needed, has it been made clear why?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The implementation step hsa 3 major steps:\n",
    "    1. Apply Preprocessing Steps\n",
    "    2. Architect Neural Network and Train\n",
    "    3. Translate Validation Data And Apply WER Score\n",
    "    \n",
    "__Step 1: Apply Preprocessing Steps__    \n",
    "1. Load the Japanese Training, English Training, Japanese validation, and English validation dataset into memory.\n",
    "\n",
    "2. Implement the Preprocessing functions to the four datasets: train.ja, train.en, test.ja, and test.en\n",
    "    - tokenize()\n",
    "    - pad()\n",
    "    - preprocess()\n",
    "\n",
    "--------\n",
    "__Step 2: Architect Neural Network and Train__    \n",
    "\n",
    "The ideal architecture for machine translation will be an deep recurrent neural network model which can take in the complex, sequential nature of language and find the appropriate translation in another. The basic archtiecture will take on the following steps:\n",
    "\n",
    "    1. Create a Sequential RNN Model From Keras\n",
    "    2. Add the Encoding Layer\n",
    "    3. Add the Decoding Layer\n",
    "    4. Add the Time Dense layer\n",
    "    5. Output Token Id Array \n",
    "\n",
    "This archtiecture will have an encoding layer which will take in the Japanese token id's, and pass the propagation to the decoder layer which will transform the data inputs into English token id's. Then the time distributed dense layer flattens the resulting tensor for a one-to-one relationship between the inputs and outputs. The basic concept of this archtecture is demonstrated in Fig4.\n",
    "\n",
    "__Fig4:__\n",
    "Encoding-Decoding layers in RNN architecture with English to French translation.\n",
    "<img src=\"images/encoder_decoder.png\">\n",
    "\n",
    "Once the model architecture has been built, the RNN model will train to detect the proper translation of a Japanese sentence to their English equivalent. The model will be saved to disk and loaded layer to test against the validation dataset.\n",
    "\n",
    "--------\n",
    "__Step 3: Translate Validation Data And Apply WER Score__\n",
    "\n",
    "After the model has been trained, the model will be applied against each line of the Japanese validation dataset. The output of each prediction will then be compared against the target English sentence to measure how closely the translation performed. The Word Error Rate function will be used to measure the rate of error between the two English sentence to determine the percentage of error in the translation.\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, the process for which metrics, algorithms, and techniques that you implemented for the given data will need to be clearly documented. It should be abundantly clear how the implementation was carried out, and discussion should be made regarding any complications that occurred during this process. Questions to ask yourself when writing this section:\n",
    "- _Is it made clear how the algorithms and techniques were implemented with the given datasets or input data?_\n",
    "- _Were there any complications with the original metrics or techniques that required changing prior to acquiring a solution?_\n",
    "- _Was there any part of the coding process e.g., writing complicated functions that should be documented?_\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinement\n",
    "Several Process Improvement steps have been applied during the implementation of this project. Those steps include:\n",
    "\n",
    "    1. Rearranging the archtiecture of the RNN Model\n",
    "    2. Adjusting Parameters for Peformance improvment (dropout rate, node count, hidden layer count)\n",
    "    3. Increasing Epic Time.\n",
    "\n",
    "First iterations of the RNN model only had a single bidirectional layer with 64 nodes in the GRU. This only yielded validation accuracy scores less than 0.40.  The initial trials were set to set a foundation of how well a simple RNN model can perform.'\n",
    "\n",
    "Second iteration of models start to reshape the architecture of the network to include a full encoding and decoder layer with two bidirectional layers to better capture the complexity of the language. Thomas Tracey was able to achieve a 97.5% validation accuracy using 128 node layers for a English to French translating RNN model. After attempting to recipricate the same, the results could not improve beyond a 0.50 validation accuracy.\n",
    "\n",
    "Third, attempts at improving performance were made by increasing the node count. The vocabulary size of this data set is considerably large (6634 Eng, and 8774 Jpn) so the ideal number of nodes will need to be considerably larger. Node sizes  several thousands large were attempted but reached resource limitations during the training data set. A node size of 1000 was selected due to it not consuming too much resource capacity to fail.\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to discuss the process of improvement you made upon the algorithms and techniques you used in your implementation. For example, adjusting parameters for certain models to acquire improved solutions would fall under the refinement category. Your initial and final solutions should be reported, as well as any significant intermediate results as necessary. Questions to ask yourself when writing this section:\n",
    "- _Has an initial solution been found and clearly reported?_\n",
    "- _Is the process of improvement clearly documented, such as what techniques were used?_\n",
    "- _Are intermediate and final solutions clearly reported as the process is improved?_\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IV. Results\n",
    "\n",
    "### Model Evaluation and Validation\n",
    "\n",
    "After the RNN model was trained, the validation datasets test.ja and test.en were used to validate the performance of the neural entwork. Afterwards the Word Error Rate was calcualted for each translation to score the performance of the model's translation abilities.\n",
    "\n",
    "The final model (which that yielded the best performance) carried the following parameters and architecture:\n",
    "\n",
    "- A Sequentiall RNN model with bidirectional encoding and decoding layers\n",
    "- A 1000 size node hidden layers\n",
    "- Learning rate of 0.001\n",
    "- Drop Out Rate of 0.2\n",
    "- Time ditributed dense layer with relu activation\n",
    "- Epoch of 20 to allow for greater training time\n",
    "\n",
    "\n",
    "__Word Error Rate Results:__\n",
    "The current model's performance is dissapointing and far from accurately translating any words or meaning from the original sentence. Current Training Validation Accuracy was at 0.64. Most of this accuracy is most liely coming from predicting common words in the sample data such as articles, pronouns, and helping verbs. The sentence that get generate convey very little meaning to a human reader. As for the WER scores, the average score was at a 0.685, minimun being 0.428 and max being 1.25. This indicates that on average, 68.5% of the each sentence has been translated incorrectly. While, the best translation was where 42.8% of the final output was correctly translated. The score of 1.25 indicates that the model additional erroroneous values than what was available in the entire sentence.\n",
    "\n",
    "__Fig5: Sample Translations Results of Validation Dataset__\n",
    "<img src=\"images/WERsamples2.png\">\n",
    "\n",
    "__Fig6: Summary Statistics of WER on 500 Validation Translations__\n",
    "<img src=\"images/WERsummary2.png\">\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, the final model and any supporting qualities should be evaluated in detail. It should be clear how the final model was derived and why this model was chosen. In addition, some type of analysis should be used to validate the robustness of this model and its solution, such as manipulating the input data or environment to see how the model’s solution is affected this is called sensitivity analysis. Questions to ask yourself when writing this section:\n",
    "- _Is the final model reasonable and aligning with solution expectations? Are the final parameters of the model appropriate?_\n",
    "- _Has the final model been tested with various inputs to evaluate whether the model generalizes well to unseen data?_\n",
    "- _Is the model robust enough for the problem? Do small perturbations changes in training data or the input space greatly affect the results?_\n",
    "- _Can results found from the model be trusted?_\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification\n",
    "\n",
    "This current model fails to meet the benchmark originally set in the proposal. Thomas Tracey achieved a 97.5% validation accuracy score in his Englsih to French [translation model](https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571) even with a similar architectural set up for the RNN model. The current RNN model struggled to even achieve 70% validation accuracy during the training phase even with larger node count within the hidden layers and a longer epoch time. Even with a marginally acceptable validation dataset, the resulting translations are incoherent to a common English speaker. The sentences the mdoel produces to not carry any sense of grammar or convey semantics. Unfortunately it can even be said that most sentences resulted in an almost random collection of words.There is much room for improvement in the data preparation and neural network model before this machine learning model can be considered a success.\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, your model’s final solution and its results should be compared to the benchmark you established earlier in the project using some type of statistical analysis. You should also justify whether these results and the solution are significant enough to have solved the problem posed in the project. Questions to ask yourself when writing this section:\n",
    "- _Are the final results found stronger than the benchmark result reported earlier?_\n",
    "- _Have you thoroughly analyzed and discussed the final solution?_\n",
    "- _Is the final solution significant enough to have solved the problem?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## V. Conclusion\n",
    "\n",
    "### Free-Form Visualization\n",
    "\n",
    "One of the more challenging aspects of this project is to account for the grammatical complexity between Japanese and English. The image below highlights via color the key words in each sentence that conveys the semantics and their associated word in the the othe language. As it can be seen, due to the grammatical differences between the two languages, the location of the word conveying meaning can be located in a significantly different location in the sentence structure. One of the pitfalls of the RNN model created for this project is that output data from one node is the input for an adjacent node. This means that the model may fail to associate words are located far from each other in a sentence index. In the benchmark model, the author translated English to French, which are grammatically much similar languages. A simple RNN model may perform much better due to the closeness in structure between the sentences in an En/Fr corpus.\n",
    "\n",
    "__Fig7: Color Highlighted Words and their Associated Translation__\n",
    "\n",
    "\n",
    "<img src=\"images/SampleSentencesColor.png\">\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to provide some form of visualization that emphasizes an important quality about the project. It is much more free-form, but should reasonably support a significant result or characteristic about the problem that you want to discuss. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant or important quality about the problem, dataset, input data, or results?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reflection\n",
    "Looking back on this project there were a few major areas that can be learned a lot from:\n",
    "\n",
    "__1. Finding a Good Corpus__\n",
    "\n",
    "At the begining of this project, a significant amount of time was spent looking for an apprpriate corpus. The internet is rich with potential data sources, however it was a challenge to narrow down to good candidates. The added challenge was that Japanese text is often unable to be tokenized from most common python packages due to the inability to split based on spaces or other key characters. Most cases a deeper understanding of Japanese linguistics is needed to place difinitive splits between tokens. That is why the Oda corpus was utlized for this project due to the pretokenized nature of the corpus. However, after going through the model training, perhaps there may have been better options for a Jp/En corpus to train from.\n",
    "\n",
    "__2. Researching different Architectures__\n",
    "\n",
    "Recurrent Neural Networks are used in multitude of applciations besides machine translations. There are many areas of research and different methodolgies depedning on language pairs. Discovering an solid architecture to model off of was difficult to find. There are many examples of simpler models that perform wonderfully with different languages as seen in the English to French translation models. However, as discovered in this project, it may not transfer well to translating between dissimilar languages.\n",
    "\n",
    "\n",
    "__3. Time Management for Training and Experiemnting__\n",
    "\n",
    "A Great deal of time was spent researching, training, testing, tweaking, and validating the machine learning model. Since it takes  a great deal of time to train a deep neural network and setting up a GPU instnace environment, less time was spent on more productive means to move the model towards better performance. During the span of this project, there was not an opportunity to experiment with opptimization methods to find the optimal parameters to implement for this model. Much time was spend manually changing parameters and experienting to see if there were any positive results. Unfortunately, most of the work was unable to yield an acceptably performing model.\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will summarize the entire end-to-end problem solution and discuss one or two particular aspects of the project you found interesting or difficult. You are expected to reflect on the project as a whole to show that you have a firm understanding of the entire process employed in your work. Questions to ask yourself when writing this section:\n",
    "- _Have you thoroughly summarized the entire process you used for this project?_\n",
    "- _Were there any interesting aspects of the project?_\n",
    "- _Were there any difficult aspects of the project?_\n",
    "- _Does the final model and solution fit your expectations for the problem, and should it be used in a general setting to solve these types of problems?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Improvement\n",
    "\n",
    "There are 3 Major Areas of Improvement:\n",
    "\n",
    "__1. Cleaner Preprocessing__\n",
    "\n",
    "As mentioned earlier, English sentences are relatively simple to tokenize due to the ease of identifying words due to the space character between them. Japanese on the other hand does nto have a consistent character to split by. Therefore there maybe tokenization gaps from excessive tokenization that may lead to a loss of semantic value. When looking at the top 20 most common tokens, most of the Japanese tokens held no meaning as singular characters while the English tokens were mostly entire words that hold meaning. Better clean up here could have avoided any redundant training over meaningles tokens.\n",
    "In addition, this project took no steps at stemming or lematizing the english corpus. This may lead to words containg the same stem or base word to being duplicated in the token dictionary. By stemming and lemmatizing during the preprocessing step, this can help reduce the vocabulary data set a model will need to learn from\n",
    "\n",
    "__2. Narrower Corpus Vocabulary__\n",
    "\n",
    "In Thomas Tracey's Englsih to French [translation model](https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571) he indicates that his corpus contained 227 unique English words and 355 unique French words. THis is a significantly smaller corpus than the Japanese corpus trained in this project whcih contained 6634 unique English tokens and 8774 unique Japanese tokens. With smaller corpus divesity, the model can be simpler and contain smaller node counts within the hidden layers. However, since the vocabulary size was so much larger for this project, the node count needed to be increased significantly to account for all the word associations to keep track. Due to the resource limit of th GPU instance used, the node count was limited to 1000.\n",
    "\n",
    "\n",
    "__3. Explore LSTM Model__\n",
    "\n",
    "As explained earlier, due to the grammatical dissimilarity between English and Japanese, the RNN model in this project suffers from the gradient decay issue where information is lost transfering to each subsequent node. Since associated word pairs between English and Japanese can be located in distant locations within a sentences, the model is unable to retain key translation pairs. To avoid this, a [Long-Term Short-Term Memory](https://en.wikipedia.org/wiki/Long_short-term_memory) can be implemented in order to retain more information that can output from distant nodes.\n",
    "\n",
    "\n",
    "[//]: # (\n",
    "In this section, you will need to provide discussion as to how one aspect of the implementation you designed could be improved. As an example, consider ways your implementation can be made more general, and what would need to be modified. You do not need to make this improvement, but the potential solutions resulting from these changes are considered and compared/contrasted to your current solution. Questions to ask yourself when writing this section:\n",
    "- _Are there further improvements that could be made on the algorithms or techniques you used in this project?_\n",
    "- _Were there algorithms or techniques you researched that you did not know how to implement, but would consider using if you knew how?_\n",
    "- _If you used your final solution as the new benchmark, do you think an even better solution exists?_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "**Before submitting, ask yourself. . .**\n",
    "\n",
    "- Does the project report you’ve written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Analysis** and **Methodology**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your analysis, methods, and results?\n",
    "- Have you properly proof-read your project report to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?\n",
    "- Is the code that implements your solution easily readable and properly commented?\n",
    "- Does the code execute without error and produce results similar to those reported?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
